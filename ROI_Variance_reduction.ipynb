{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c06426b",
   "metadata": {},
   "source": [
    "# This is a notebook for testing a variance reduction technique using langevin dynamics to sample from a posterior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc778b",
   "metadata": {},
   "source": [
    "## We have: \n",
    "\n",
    "### a set of observations $y = Ax^* (y \\in \\mathbb{R}^m, A \\in \\mathbb{R}^{m \\times n} x \\in \\mathbb{R}^n)$ \n",
    "### ncsn $s(\\theta, x) \\simeq \\nabla \\log p(x)$ \n",
    "### region of interest $ROI \\subseteq \\{1,2,\\dots,n\\}$ \n",
    "\n",
    "## We want: recovered $\\hat{x}$ where $x[ROI] = x^*[ROI]$ \n",
    "\n",
    "### we propose to do this by getting a minimum variance estimate for ROI, possibly at the expense of bias in ROI and increased variance in [N] / ROI  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b77c3",
   "metadata": {},
   "source": [
    "## Preliminaries: define the paths to useful files and import needed stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/sriram/Projects/ncsnv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/home/sriram/Projects/ncsnv2/exp/logs/celeba/checkpoint_210000.pth\"\n",
    "config_path = \"/home/sriram/Projects/ncsnv2/configs/celeba.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import dict2namespace\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "new_config = dict2namespace(config)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "new_config.device = device\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=1234, help='Random seed')\n",
    "parser.add_argument('--exp', type=str, default='exp', help='Path for saving running related data.')\n",
    "\n",
    "args = parser.parse_args([\"--seed\", \"2240\", \"--exp\", \"/home/sriram/Projects/ncsnv2/exp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d8936",
   "metadata": {},
   "source": [
    "## Grab the data and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset, data_transform, inverse_data_transform\n",
    "\n",
    "_, test_dataset = get_dataset(args, new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True,\n",
    "                          num_workers=8, drop_last=True)\n",
    "\n",
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = next(test_iter)[0]\n",
    "test_sample = test_sample.to(new_config.device)\n",
    "test_sample = data_transform(new_config, test_sample)\n",
    "test_sample = test_sample.cpu()\n",
    "\n",
    "print(\"SHAPE: \", test_sample.shape)\n",
    "print(\"MIN: \", torch.min(test_sample))\n",
    "print(\"MAX: \", torch.max(test_sample))\n",
    "print(\"MEAN: \", torch.mean(test_sample))\n",
    "print(\"STD: \", torch.std(test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "grid_img = torchvision.utils.make_grid(test_sample, nrow=4)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac3613",
   "metadata": {},
   "source": [
    "## Grab the appropriate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ncsnv2 import NCSNv2\n",
    "from models.ema import EMAHelper\n",
    "from models import get_sigmas\n",
    "\n",
    "new_config.input_dim = new_config.data.image_size ** 2 * new_config.data.channels\n",
    "\n",
    "score = NCSNv2(new_config).to(new_config.device)\n",
    "score = torch.nn.DataParallel(score)\n",
    "\n",
    "#Set up the exponential moving average\n",
    "if new_config.model.ema:\n",
    "    ema_helper = EMAHelper(mu=new_config.model.ema_rate)\n",
    "    ema_helper.register(score)\n",
    "\n",
    "states = torch.load(ckpt_path)\n",
    "score.load_state_dict(states[0])\n",
    "### Make sure we can resume with different eps\n",
    "states[1]['param_groups'][0]['eps'] = new_config.optim.eps\n",
    "\n",
    "if new_config.model.ema:\n",
    "    ema_helper.load_state_dict(states[4])\n",
    "\n",
    "#grab all L noise levels\n",
    "sigmas = get_sigmas(new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = ema_helper.ema_copy(score)\n",
    "\n",
    "test_score.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e845725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUMBER OF NOISE LEVELS: \", sigmas.shape.numel())\n",
    "print(\"FIRST: \", sigmas[0].item(), \" LAST: \", sigmas[-1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180b9f1",
   "metadata": {},
   "source": [
    "## Create some measurements of an image and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(test_iter)[0][0]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRectMask(h_offset=0, w_offset=0, height=10, width=35, tensor_like=None, \\\n",
    "                img_height=64, img_width=64, num_channels=3):\n",
    "    \n",
    "    if tensor_like is not None:\n",
    "        mask_tensor = torch.ones_like(tensor_like)\n",
    "    else:\n",
    "        mask_tensor = torch.ones(num_channels, img_height, img_width)\n",
    "    \n",
    "    mask_tensor[:, h_offset:h_offset+height, w_offset:w_offset+width] = 0\n",
    "    \n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = getRectMask(h_offset=27, w_offset=15, tensor_like = x)\n",
    "\n",
    "y = A * x\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(y.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35981f38",
   "metadata": {},
   "source": [
    "## First, run Langevin dynamics on the single image to sample multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "\n",
    "x = x.unsqueeze(0).repeat(N, 1, 1, 1)\n",
    "y = y.unsqueeze(0).repeat(N, 1, 1, 1)\n",
    "\n",
    "print(\"X shape: \", x.shape)\n",
    "print(\"Y shape: \", y.shape)\n",
    "print(\"A shape: \", A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0208d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(new_config.device)\n",
    "A = A.to(new_config.device)\n",
    "y = y.to(new_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e22c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGLD_inpainting(x_mod, x, A, scorenet, sigmas, T=5, step_lr=3.3e-6, \\\n",
    "                   final_only=False, verbose=False, denoise=True, decimate=False):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #create a negative mask from A\n",
    "    A_trans = -A + 1  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for c, sigma in enumerate(sigmas):\n",
    "            #if we choose to decimate, only update once every decimate steps\n",
    "            if decimate is not False:\n",
    "                if c % decimate != 0:\n",
    "                    continue \n",
    "            #construct the noise level labels to give to scorenet for scaling \n",
    "            labels = torch.ones(x_mod.shape[0], device=x_mod.device) * c\n",
    "            labels = labels.long()\n",
    "            \n",
    "            step_size = step_lr * (sigma / sigmas[-1]) ** 2\n",
    "            \n",
    "            y = A * x + torch.randn_like(x_mod) * sigma\n",
    "            \n",
    "            for s in range(T):\n",
    "                #prior\n",
    "                grad = scorenet(x_mod, labels)\n",
    "                \n",
    "                #draw noise\n",
    "                noise = torch.randn_like(x_mod)\n",
    "                \n",
    "                #prior step\n",
    "                x_mod = x_mod + step_size * grad + noise * torch.sqrt(step_size * 2)\n",
    "                \n",
    "                #likelihood step\n",
    "                x_mod = x_mod * A_trans + y * A\n",
    "                \n",
    "                #logging\n",
    "                grad_norm = torch.norm(grad.view(grad.shape[0], -1), dim=-1).mean()\n",
    "                noise_norm = torch.norm(noise.view(noise.shape[0], -1), dim=-1).mean()\n",
    "                image_norm = torch.norm(x_mod.view(x_mod.shape[0], -1), dim=-1).mean()\n",
    "                snr = torch.sqrt(step_size / 2.) * grad_norm / noise_norm\n",
    "                grad_mean_norm = torch.norm(grad.mean(dim=0).view(-1)) ** 2 * sigma ** 2\n",
    "                \n",
    "                if not final_only:\n",
    "                    images.append(x_mod.to('cpu'))\n",
    "                if verbose:\n",
    "                    print(\"level: {}, step_size: {}, grad_norm: {}, image_norm: {}, snr: {}, grad_mean_norm: {}\".format(\n",
    "                        c, step_size, grad_norm.item(), image_norm.item(), snr.item(), grad_mean_norm.item()))\n",
    "                \n",
    "        if denoise:\n",
    "            last_noise = (len(sigmas) - 1) * torch.ones(x_mod.shape[0], device=x_mod.device)\n",
    "            last_noise = last_noise.long()\n",
    "            x_mod = x_mod + sigmas[-1] ** 2 * scorenet(x_mod, last_noise)\n",
    "            images.append(x_mod.to('cpu'))\n",
    "\n",
    "        if final_only:\n",
    "            return [x_mod.to('cpu')]\n",
    "        else:\n",
    "            return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mod = torch.rand(N, 3, 64, 64, device=new_config.device)\n",
    "\n",
    "images = SGLD_inpainting(x_mod=x, x=x, A=A, scorenet=test_score, sigmas=sigmas, \\\n",
    "                         T=5, step_lr=3.3e-6, final_only=True, verbose=True, denoise=True,\n",
    "                         decimate = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a177771",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = images[0]\n",
    "\n",
    "plt.figure(figsize=(9, 18))\n",
    "grid_img = torchvision.utils.make_grid(results, nrow=4)\n",
    "plt.imshow(grid_img.permute(1, 2, 0), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355eabd",
   "metadata": {},
   "source": [
    "## Calculate the variance in the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = -A + 1\n",
    "\n",
    "x_hat_ROI = results.to(new_config.device) * ROI\n",
    "x_hat_ROI_mean = torch.mean(x_hat_ROI, dim=0)\n",
    "\n",
    "print(\"ROI Img Shape: \", x_hat_ROI.shape)\n",
    "print(\"Mean Shape: \", x_hat_ROI_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_var = torch.norm(x_hat_ROI - x_hat_ROI_mean, p=2)**2 / N\n",
    "\n",
    "print(ROI_var.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf2f56",
   "metadata": {},
   "source": [
    "## Repeat the process for non-pixel-space forward operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(test_iter)[0][0]\n",
    "\n",
    "plt.imshow(x.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b88ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "\n",
    "C, H, W = list(x.size())\n",
    "\n",
    "x = x.unsqueeze(0).repeat(N, 1, 1, 1)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = int(0.1 * C * H * W)\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (1 / np.sqrt(m)) * torch.randn(m, C*H*W)\n",
    "\n",
    "y = torch.matmul(A, torch.flatten(x, start_dim=1).T).T\n",
    "\n",
    "print(\"A shape: \", A.shape)\n",
    "print(\"y shape: \", y.shape)\n",
    "print(\"x shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(new_config.device)\n",
    "A = A.to(new_config.device)\n",
    "y = y.to(new_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_likelihood_grad(A, y, x_hat, c_list):\n",
    "    \"\"\"\n",
    "    Returns a likelihood gradient given a system and weighting.\n",
    "    p(y|x_hat) = (1/2)||C(y - Ax_hat)||_2^2 where C is a square matrix with c_i on the diagonal.\n",
    "    gradient = (A^T)(C^T)[CAx_hat - Cy]\n",
    "             = (A^T)(C^T)(CAx_hat) - (A^T)(C^T)Cy\n",
    "             = (A^T)(C^2)Ax_hat - (A^T)(C^2)y\n",
    "    \n",
    "    Arguments:\n",
    "        A: measurement operator [m, n=H*C*W]\n",
    "        y: measurement operator [N, m]\n",
    "        x: data [N, C, H, W]\n",
    "        c: weights for each row of reconstruction loss [m]\n",
    "    \"\"\"\n",
    "    \n",
    "    Ax_hat = torch.matmul(A, torch.flatten(x_hat, start_dim=1).T).T #[N, m]\n",
    "    \n",
    "    C_squared = torch.diag(torch.flatten(c_list)).to(new_config.device) #[m, m]\n",
    "    \n",
    "    hat_term = torch.matmul(C_squared, Ax_hat.T).T #[N, m]\n",
    "    hat_term = torch.matmul(A.T, hat_term.T).T #[N, n]\n",
    "    \n",
    "    meas_term = torch.matmul(C_squared, y.T).T #[N, m]\n",
    "    meas_term = torch.matmul(A.T, meas_term.T).T #[N, n]\n",
    "    \n",
    "    return (hat_term - meas_term).view(list(x_hat.shape)) #[N, n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c97d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ROI_loss(x_hat, ROI):\n",
    "    N = list(x_hat.shape)[0]\n",
    "    \n",
    "    x_hat_ROI = x_hat * ROI\n",
    "    x_hat_ROI_mean = torch.mean(x_hat_ROI, dim=0)\n",
    "    \n",
    "    ROI_var = torch.norm(x_hat_ROI - x_hat_ROI_mean, p=2)**2 / N\n",
    "\n",
    "    return ROI_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab73295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGLD_inverse(x_mod, y, A, c_list, scorenet, sigmas, x=None, T=5, step_lr=3.3e-6, \\\n",
    "                 verbose=False, denoise=True, decimate=False):\n",
    "    \n",
    "    if x is not None:\n",
    "        mse = torch.nn.MSELoss()\n",
    "    \n",
    "    for c, sigma in enumerate(sigmas):\n",
    "        #if we choose to decimate, only update once every decimate steps\n",
    "        if decimate is not False:\n",
    "            if c % decimate != 0 or c == 0: #the second part after and is optional lol\n",
    "                continue \n",
    "\n",
    "        with torch.no_grad():\n",
    "        #construct the noise level labels to give to scorenet for scaling \n",
    "            labels = torch.ones(x_mod.shape[0], device=x_mod.device) * c\n",
    "            labels = labels.long()\n",
    "\n",
    "            step_size = step_lr * (sigma / sigmas[-1]) ** 2\n",
    "\n",
    "        for s in range(T):\n",
    "            #prior\n",
    "            with torch.no_grad():\n",
    "                grad = scorenet(x_mod, labels)\n",
    "                grad_norm = torch.norm(grad.view(grad.shape[0], -1), dim=-1).mean()\n",
    "\n",
    "            #likelihood\n",
    "            mle_grad = calc_likelihood_grad(A=A, y=y, x_hat=x_mod, c_list=c_list)\n",
    "            with torch.no_grad():\n",
    "                mle_grad_norm = torch.norm(mle_grad.view(mle_grad.shape[0], -1), dim=-1).mean()\n",
    "\n",
    "            grad = grad - (mle_grad / sigma**2)\n",
    "            #grad = grad - mle_grad\n",
    "\n",
    "            #draw noise\n",
    "            noise = torch.randn_like(x_mod)\n",
    "\n",
    "            #prior step\n",
    "            x_mod = x_mod + step_size * grad + noise * torch.sqrt(step_size * 2)\n",
    "\n",
    "            #logging\n",
    "            with torch.no_grad():\n",
    "                if x is not None:\n",
    "                    true_mse = mse(x_mod, x)\n",
    "\n",
    "                    if verbose:\n",
    "                        print(\"level: {}, step_size: {:.3f}, grad_norm: {:.3f}, mle_grad_norm: {:.3f}, true mse: {:.3f}\".format(\n",
    "                            c, step_size, grad_norm.item(), mle_grad_norm.item(), true_mse.item()))\n",
    "\n",
    "    if denoise:\n",
    "        last_noise = (len(sigmas) - 1) * torch.ones(x_mod.shape[0], device=x_mod.device)\n",
    "        last_noise = last_noise.long()\n",
    "        x_mod = x_mod + sigmas[-1] ** 2 * scorenet(x_mod, last_noise)\n",
    "\n",
    "    return x_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRectMask(h_offset=0, w_offset=0, height=10, width=35, tensor_like=None, \\\n",
    "                img_height=64, img_width=64, num_channels=3):\n",
    "    \n",
    "    if tensor_like is not None:\n",
    "        mask_tensor = torch.zeros_like(tensor_like)\n",
    "    else:\n",
    "        mask_tensor = torch.zeros(num_channels, img_height, img_width)\n",
    "    \n",
    "    mask_tensor[:, h_offset:h_offset+height, w_offset:w_offset+width] = 1\n",
    "    \n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5021a9",
   "metadata": {},
   "source": [
    "### create the hypterparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = torch.ones(m, device=new_config.device, requires_grad=False)\n",
    "#c_list = c_list * 1\n",
    "c_list = c_list.requires_grad_()\n",
    "\n",
    "print(c_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58382734",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = getRectMask(h_offset=27, w_offset=15).to(new_config.device)\n",
    "\n",
    "print(ROI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e20a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(ROI.cpu(), nrow=4)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c52813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "opt = optim.Adam([{'params': c_list}], lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda96ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "x_mod = torch.rand(N, C, H, W, device=new_config.device, requires_grad=False)\n",
    "\n",
    "langevin_vars = []\n",
    "\n",
    "num_iters = 5\n",
    "\n",
    "for epoch in tqdm(range(num_iters)):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    x_hat = SGLD_inverse(x_mod, y, A, c_list, test_score, sigmas, x=x, \\\n",
    "                         verbose=True, denoise=False, decimate=False)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    grid_img = torchvision.utils.make_grid(x_hat.cpu(), nrow=4)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    \n",
    "    loss = calc_ROI_loss(x_hat, ROI)\n",
    "    \n",
    "    langevin_vars.append(loss.item())\n",
    "    print(\"ROI VARIANCE: \", loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(c_list)\n",
    "    \n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf64463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
